{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io as io\n",
    "import PIL as Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter \n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import json\n",
    "from matplotlib import cm as CM\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_density(ground_truth):\n",
    "    '''Generates a density map using Gaussian filter transformation.'''\n",
    "    density = np.zeros(ground_truth.shape, dtype=np.float32)\n",
    "    ground_truth_count = np.count_nonzero(ground_truth)\n",
    "    \n",
    "    if ground_truth_count == 0:\n",
    "        return density\n",
    "\n",
    "    # Find out the K nearest neighbours using a KDTree\n",
    "    index_of_nonzero_elements = np.nonzero(ground_truth)\n",
    "    points = np.array(list(zip(index_of_nonzero_elements[1].ravel(), index_of_nonzero_elements[0].ravel())))\n",
    "    leafsize = 2048\n",
    "    \n",
    "    # build kdtree\n",
    "    tree = spatial.KDTree(points.copy(), leafsize=leafsize)\n",
    "    # query kdtree\n",
    "    distances, _ = tree.query(points, k=4)\n",
    "        \n",
    "    for i, point in enumerate(points):\n",
    "        point_2d = np.zeros(ground_truth.shape, dtype=np.float32)\n",
    "        point_2d[point[1],point[0]] = 1.\n",
    "        if ground_truth_count > 1:\n",
    "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
    "        else:\n",
    "            sigma = np.average(np.array(ground_truth.shape))/2./2. #case: 1 point\n",
    "        \n",
    "        #Convolve with the gaussian filter\n",
    "        density += gaussian_filter(point_2d, sigma, mode='constant')\n",
    "    return density\n",
    "\n",
    "\n",
    "def create_density_maps(img_paths):\n",
    "    \"\"\"For each path given, loads the corresponding image and its ground truth. \n",
    "    The ground truth can be seen as the x,y coordinates of the detected personds. \n",
    "    Out of this ground truth a hot encoded matrix is generated for the image. \n",
    "    This is a matrix with same shape as the image, and whose all values are 0 except\n",
    "    for those where a person is found (with value 1). From this matrix the density \n",
    "    map is constructed via gaussian transformations in another function and saved in h5 file. \"\"\"\n",
    "    for img_path in tqdm(img_paths):\n",
    "        # Load sparse matrix\n",
    "        mat_file = io.loadmat(img_path.replace('.jpg','.mat').replace('images','ground_truth').replace('IMG_','GT_IMG_'))\n",
    "        \n",
    "        #Read image\n",
    "        img= plt.imread(img_path)\n",
    "        # Create a zero matrix of image size\n",
    "        k = np.zeros((img.shape[0],img.shape[1]))\n",
    "        \n",
    "        ground_truth = mat_file[\"image_info\"][0,0][0,0][0]\n",
    "\n",
    "        #Generate hot encoded matrix of sparse matrix\n",
    "        for i in range(len(ground_truth)):\n",
    "            if int(ground_truth[i][1])<img.shape[0] and int(ground_truth[i][0])<img.shape[1]:\n",
    "                k[int(ground_truth[i][1]), int(ground_truth[i][0])]=1\n",
    "        \n",
    "        # generate density map\n",
    "        k = gaussian_filter_density(k)\n",
    "        \n",
    "        # File path to save density map\n",
    "        file_path = img_path.replace('.jpg','.h5').replace('images','density_maps')\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(os.path.dirname(file_path)):\n",
    "            os.makedirs(os.path.dirname(file_path))\n",
    "\n",
    "        with h5py.File(file_path, 'w') as hf:\n",
    "                hf['density'] = k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data\\shangai_dataset'\n",
    "part_A_train = os.path.join(root,'part_A\\\\train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A\\\\test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B\\\\train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B\\\\test_data','images')\n",
    "path_sets = [part_A_train, part_A_test, part_B_train, part_B_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1198\n",
      "Example of image path: data\\shangai_dataset\\part_A\\train_data\\images\\IMG_1.jpg\n"
     ]
    }
   ],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)\n",
    "print(f'Number of images: {len(img_paths)}')\n",
    "print(f'Example of image path: {img_paths[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create density maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1198/1198 [3:31:44<00:00, 10.61s/it] \n"
     ]
    }
   ],
   "source": [
    "create_density_maps(img_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the density map of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "img_22 = Image.open(img_paths[22])\n",
    "plt.imshow(img_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\shangai_dataset\\part_A\\train_data\\ground\\IMG_119.h5\n"
     ]
    }
   ],
   "source": [
    "# Its density map\n",
    "file_path_22 = img_paths[22].replace('.jpg','.h5').replace('images','ground') \n",
    "ground_truth_file_22 = h5py.File(file_path_22,'r')\n",
    "groundtruth_22 = np.asarray(ground_truth_file_22['density'])\n",
    "plt.imshow(groundtruth_22,cmap=CM.jet)\n",
    "print(\"Sum = \" ,np.sum(groundtruth_22))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mall dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mall = 'data\\mall_dataset'\n",
    "images_mall = np.load('data\\mall_dataset\\images.npy')\n",
    "labels_mall = np.load('data\\mall_dataset\\labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image array shape: (2000, 480, 640, 3)\n",
      "Labels array shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'Image array shape: {images_mall.shape}')\n",
    "print(f'Labels array shape: {labels_mall.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1600, 480, 640, 3)\n",
      "y_train shape: (1600, 1)\n",
      "X_test shape: (400, 480, 640, 3)\n",
      "y_test shape: (400, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mall, X_test_mall, y_train_mall, y_test_mall = train_test_split(images_mall, labels_mall, test_size=0.2, random_state=42)\n",
    "\n",
    "# print the shapes of the train and test sets\n",
    "print('X_train shape:', X_train_mall.shape)\n",
    "print('y_train shape:', y_train_mall.shape)\n",
    "print('X_test shape:', X_test_mall.shape)\n",
    "print('y_test shape:', y_test_mall.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
